---
title: "Longform&TwitterDescriptiveStats"
output:
  html_document:
    keep_md: yes
---
//Pull Data Files (still need to work on this part)
LF <- read.csv('data/LFTasteCoded_final.csv')
Twitter <- read.csv('Users/Ava/Desktop/describing_data_git/classtest_2/data/ecig_no_duplicates_taste_final.csv')

//Longform file
LF <- LFTasteCoded_final
sum(LFTaste$window_taste)
sum(LFTaste$ecig)
sum(LFecig$window_taste)
LFTaste <- LFecig[which(LFecig$window_taste == "1"), ]
LFecig <- LF[which(LF$ecig == "1"), ]

//Describe longform all sources
table(LFecig$Source)
write.table(LFTaste, "/Users/Ava/Desktop/describing_data_git/classtest_2/data/LFTaste.csv", row.names = FALSE, col.names = T, sep = ",")
summary (LFTaste)

//Random Sample
library(httr)
LFTaste300 = sample(LFecig$ArticleID[which(LFecig$window_taste=="1")],300)
write.table(LFTaste300, "/Users/Ava/Desktop/describing_data_git/classtest_2/data/LFTaste300.csv", row.names = FALSE, col.names = T, sep = ",")
LFTaste300 <- read.csv("/Users/Ava/Desktop/describing_data_git/classtest_2/data/LFTaste300.csv")
colnames(LFTaste300) <- c("ArticleID")
//pull in and simplify file with all article content 
metadata<-read_excel("Desktop/describing_data_git/classtest_2/data/ak_window_taste_longform_all_metadata.xlsx")
view(metadata)
simplelf<-metadata[,c('ArticleContent','ArticleID', 'ArticleTitle', 'SourceTitle')]
simplelf<- simplelf[c("ArticleID", "SourceTitle", "ArticleTitle", "ArticleContent")]
//merge random sample with simplified content file 
rslf <- merge(LFTaste300, simplelf)
//save as csv
write.table(rslf, "/Users/Ava/Desktop/describing_data_git/classtest_2/data/LFTaste300IDContent.csv", row.names = FALSE, col.names = T, sep = ",")
LFTaste300IDContent <- rslf
##write to file.
write.table(LFTaste300IDContent,"/Users/Ava/Desktop/describing_data_git/classtest_2/data/LFTaste300IDContent.txt",row.names=F,col.names=T,sep="\t")

##fix space issues.
ArticleContent<-vector(mode='character',length=dim(rslf)[1])
ArticleTitle<-vector(mode='character',length=dim(rslf)[1])
rslf$ArticleContent<-gsub("\t","\ ",rslf$ArticleContent)
rslf$ArticleContent<-gsub("\r","\ ",rslf$ArticleContent)
rslf$ArticleContent<-gsub("\n","\ ",rslf$ArticleContent)
rslf$ArticleContent<-gsub("\ +","\ ",rslf$ArticleContent)

##write to file with spacing issues adjusted
write.table(rslf,"/Users/Ava/Desktop/describing_data_git/classtest_2/data/LFTaste300IDContent3.txt",row.names=F,col.names=T,sep="\t")

//Twitter Random Sample
Twitter<- ecig_no_duplicates_taste_final
Twittertaste <- Twitter[which(Twitter$taste == "TRUE"), ]
//Pull Random Sample with just Article IDS
TwitterTaste300 <- sample((Twittertaste$ArticleID), size=300, replace=F)
write.table(TwitterTaste300, "/Users/Ava/Desktop/describing_data_git/classtest_2/data/TwitterTaste300.csv", row.names = FALSE, col.names = T, sep = ",")

//Reduce twitter file to article id and article content 
simpletwitter <- Twittertaste[,c('ArticleID','ArticleContent')]
//Merge random sample file with big file on article id 
rst <- merge(TwitterTaste300, simpletwitter, by.x='x', by.y='ArticleID')
colnames(rst) <- c("ArticleID", "ArticleContent")
write.table(rst, "/Users/Ava/Desktop/describing_data_git/classtest_2/data/TwitterTaste300IDContent.csv", row.names = FALSE, col.names = T, sep = ",")
TwitterTaste300IDContent <- read.csv("/Users/Ava/Desktop/describing_data_git/classtest_2/data/TwitterTaste300IDContent.csv")
##write to file.
write.table(TwitterTaste300IDContent,"/Users/Ava/Desktop/describing_data_git/classtest_2/data/TwitterTaste300IDContent.txt",row.names=F,col.names=T,sep="\t")





```{r echo=TRUE}
//Describe longform all sources
table(LFecig$Source)
table(LFecig$Source,LFcig$SpecificSourceTitle)

//Describe longform flavor by source type and source 
table(LFTasteSource)
table(LFTaste$Source,LFTaste$SpecificSourceTitle)


